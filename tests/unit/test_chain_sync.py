import pytest
from unittest.mock import MagicMock, AsyncMock, patch
from types import SimpleNamespace
import torch
import asyncio
from tests.mocks.subtensor import MockSubtensor
from tests.mocks.wallet import MockWallet
from tests.mocks.metagraph import MockMetagraph

from tplr.chain_sync import ChainSync
from tplr.schemas import Bucket

# Import existing mocks

# Mark all tests as async
pytestmark = pytest.mark.asyncio


class TestChainSyncBasics:
    """Test basic initialization and attributes of ChainSync"""

    @pytest.fixture
    async def chain_sync_instance(self, mock_wallet, mock_metagraph):
        """Create chain sync instance with standard mocks"""
        config = MagicMock()
        netuid = 1

        # Use existing mocks
        hparams = SimpleNamespace(
            blocks_per_window=100,
            topk_peers=10,
            minimum_peers=3,
            max_topk_peers=10,
            eval_stake_threshold=20000,
        )

        # Create instance
        chain_sync = ChainSync(
            config=config,
            netuid=netuid,
            metagraph=mock_metagraph,
            hparams=hparams,
            fetch_interval=60,
            wallet=mock_wallet,
        )

        return chain_sync

    async def test_initialization(self, chain_sync_instance):
        """Test ChainSync initialization"""
        # Check basic attributes
        assert chain_sync_instance.netuid == 1
        assert chain_sync_instance.window_duration == 100
        assert chain_sync_instance.current_block == 0
        assert chain_sync_instance.current_window == 0

        # Check collections
        assert isinstance(chain_sync_instance.commitments, dict)
        assert isinstance(chain_sync_instance.peers, list)
        assert isinstance(chain_sync_instance.eval_peers, dict)
        assert isinstance(chain_sync_instance.active_peers, set)
        assert isinstance(chain_sync_instance.inactive_peers, set)


class TestCommitmentManagement:
    """Test commitment fetching and management"""

    @pytest.fixture
    async def chain_sync_instance(self, mock_wallet, mock_metagraph):
        """Create chain sync instance with mocked commitments"""
        # Setup hparams
        hparams = SimpleNamespace(
            blocks_per_window=100, topk_peers=10, minimum_peers=3, max_topk_peers=10
        )

        # Create instance
        chain_sync = ChainSync(
            config=MagicMock(),
            netuid=1,
            metagraph=mock_metagraph,
            hparams=hparams,
            wallet=mock_wallet,
        )

        # Mock subtensor method
        chain_sync.subtensor = MagicMock()
        chain_sync.get_commitments = AsyncMock(return_value={})

        # Add some bucket info manually
        chain_sync.commitments = {
            1: Bucket(
                name="bucket1",
                account_id="account1",
                access_key_id="key1",
                secret_access_key="secret1",
            ),
            2: Bucket(
                name="bucket2",
                account_id="account2",
                access_key_id="key2",
                secret_access_key="secret2",
            ),
            3: Bucket(
                name="bucket3",
                account_id="account3",
                access_key_id="key3",
                secret_access_key="secret3",
            ),
        }

        return chain_sync

    async def test_get_bucket(self, chain_sync_instance):
        """Test getting a bucket for a specific UID"""
        # Get bucket for existing UID
        bucket = chain_sync_instance.get_bucket(1)
        assert bucket is not None
        assert bucket.name == "bucket1"

        # Get bucket for non-existing UID
        bucket = chain_sync_instance.get_bucket(999)
        assert bucket is None


class TestPeerTracking:
    """Test peer tracking and selection"""

    @pytest.fixture
    async def chain_sync_instance(self, mock_wallet, mock_metagraph):
        """Create chain sync instance with mock peer data"""
        # Setup hparams
        hparams = SimpleNamespace(
            blocks_per_window=100,
            topk_peers=40,  # 40% of peers
            minimum_peers=2,
            max_topk_peers=3,
        )

        # Create instance
        chain_sync = ChainSync(
            config=MagicMock(),
            netuid=1,
            metagraph=mock_metagraph,
            hparams=hparams,
            wallet=mock_wallet,
        )

        # Setup active peers
        chain_sync.active_peers = set([1, 2, 3, 4, 5])

        return chain_sync

    async def test_set_gather_peers(self, chain_sync_instance):
        """Test selecting peers for gradient gathering"""
        # Set gather peers
        chain_sync_instance.set_gather_peers()

        # Check we selected correct number of peers
        assert (
            len(chain_sync_instance.peers) <= chain_sync_instance.hparams.max_topk_peers
        )
        assert (
            len(chain_sync_instance.peers) >= chain_sync_instance.hparams.minimum_peers
        )

        # The highest incentive peers should be selected from active peers
        assert all(
            p in chain_sync_instance.active_peers for p in chain_sync_instance.peers
        )

    async def test_empty_active_peers(self, chain_sync_instance):
        """Test handling empty active peers list"""
        # Clear active peers
        chain_sync_instance.active_peers = set()

        # Set gather peers
        chain_sync_instance.set_gather_peers()

        # Check result
        assert chain_sync_instance.peers == []


class TestValidatorIdentification:
    """Test finding highest staked validator"""

    @pytest.fixture
    async def chain_sync_instance(self, mock_wallet, mock_metagraph):
        """Create chain sync instance with validators in metagraph"""
        # Setup hparams
        hparams = SimpleNamespace(blocks_per_window=100)

        # Create instance
        chain_sync = ChainSync(
            config=MagicMock(),
            netuid=1,
            metagraph=mock_metagraph,
            hparams=hparams,
            wallet=mock_wallet,
        )

        # Add bucket info
        chain_sync.commitments = {
            0: Bucket(
                name="bucket0",
                account_id="account0",
                access_key_id="key0",
                secret_access_key="secret0",
            ),
            1: Bucket(
                name="bucket1",
                account_id="account1",
                access_key_id="key1",
                secret_access_key="secret1",
            ),
            2: Bucket(
                name="bucket2",
                account_id="account2",
                access_key_id="key2",
                secret_access_key="secret2",
            ),
            3: Bucket(
                name="bucket3",
                account_id="account3",
                access_key_id="key3",
                secret_access_key="secret3",
            ),
            4: Bucket(
                name="bucket4",
                account_id="account4",
                access_key_id="key4",
                secret_access_key="secret4",
            ),
            5: Bucket(
                name="bucket5",
                account_id="account5",
                access_key_id="key5",
                secret_access_key="secret5",
            ),
            6: Bucket(
                name="bucket6",
                account_id="account6",
                access_key_id="key6",
                secret_access_key="secret6",
            ),
            7: Bucket(
                name="bucket7",
                account_id="account7",
                access_key_id="key7",
                secret_access_key="secret7",
            ),
            8: Bucket(
                name="bucket8",
                account_id="account8",
                access_key_id="key8",
                secret_access_key="secret8",
            ),
            9: Bucket(
                name="bucket9",
                account_id="account9",
                access_key_id="key9",
                secret_access_key="secret9",
            ),
        }

        return chain_sync

    async def test_get_highest_stake_validator(self, chain_sync_instance):
        """Test finding the highest staked validator"""
        # Get highest stake validator bucket
        bucket, uid = await chain_sync_instance._get_highest_stake_validator_bucket()

        # Check that we got a bucket and a UID (specific values depend on mock metagraph)
        assert bucket is not None
        assert uid is not None
        # The bucket name should follow our format
        assert bucket.name == f"bucket{uid}"

    async def test_no_validators(self):
        """Test handling when no validators exist"""
        # Create metagraph with no validators (all trust = 0)
        metagraph = MagicMock()
        metagraph.uids = torch.tensor([1, 2, 3])
        metagraph.T = torch.tensor([0.0, 0.0, 0.0])

        # Create instance
        chain_sync = ChainSync(
            config=MagicMock(),
            netuid=1,
            metagraph=metagraph,
            hparams=SimpleNamespace(blocks_per_window=100),
        )

        # Get highest stake validator bucket (should be None)
        bucket, uid = await chain_sync._get_highest_stake_validator_bucket()
        assert bucket is None
        assert uid is None


class TestFetchBackground:
    """Test background fetching task"""

    @pytest.fixture
    async def chain_sync_instance(self, mock_wallet, mock_metagraph):
        """Create chain sync instance for testing background fetching"""
        # Create instance
        chain_sync = ChainSync(
            config=MagicMock(),
            netuid=1,
            metagraph=mock_metagraph,
            hparams=SimpleNamespace(blocks_per_window=100),
            fetch_interval=0.1,  # Fast interval for testing
            wallet=mock_wallet,
        )

        # Mock methods used by background task
        chain_sync.get_commitments = AsyncMock(return_value={1: MagicMock()})
        chain_sync.update_peers_with_buckets = MagicMock()

        # Mock the periodic task to prevent it from actually running
        chain_sync._fetch_commitments_periodically = AsyncMock()

        yield chain_sync

        # Clean up the task if it exists
        if chain_sync._fetch_task is not None:
            chain_sync._fetch_task.cancel()

    async def test_commitment_fetcher_start(self, chain_sync_instance):
        """Test starting the commitment fetcher"""
        # Initially no task
        assert chain_sync_instance._fetch_task is None

        # Patch create_task to track if it was called
        with patch("asyncio.create_task") as mock_create_task:
            chain_sync_instance.start_commitment_fetcher()
            mock_create_task.assert_called_once()

        # Task should be set
        assert chain_sync_instance._fetch_task is not None


class TestErrorHandling:
    """Test error handling in ChainSync"""

    @pytest.fixture
    async def chain_sync_instance(self, mock_wallet, mock_metagraph):
        """Create chain sync instance for testing error handling"""
        chain_sync = ChainSync(
            config=MagicMock(),
            netuid=1,
            metagraph=mock_metagraph,
            hparams=SimpleNamespace(blocks_per_window=100),
            wallet=mock_wallet,
        )

        return chain_sync

    async def test_get_commitments_error(self, chain_sync_instance):
        """Test error handling in get_commitments"""
        # Simply mock the get_commitments method directly
        # This is simpler and avoids the issue with unawaited coroutines
        with patch.object(
            chain_sync_instance, "get_commitments", new_callable=AsyncMock
        ) as mock_get_commitments:
            # Set up the mock to return empty dict
            mock_get_commitments.return_value = {}

            # Call the method and verify result
            commitments = await chain_sync_instance.get_commitments()
            assert commitments == {}

            # Verify the mock was called
            mock_get_commitments.assert_awaited_once()

        # Now test with the real implementation handling an exception
        if (
            hasattr(chain_sync_instance, "subtensor")
            and chain_sync_instance.subtensor is not None
        ):
            # Only if subtensor already exists
            orig_subtensor = chain_sync_instance.subtensor
            try:
                # Create a mock that raises an exception
                mock_subtensor = MagicMock()

                # We'll use side_effect to define what happens when method is called
                async def mock_get_commitment(*args, **kwargs):
                    raise Exception("Test error")

                mock_subtensor.get_commitment = mock_get_commitment
                chain_sync_instance.subtensor = mock_subtensor

                # Test the exception handling
                result = await chain_sync_instance.get_commitments()
                assert result == {}
            finally:
                # Restore original
                chain_sync_instance.subtensor = orig_subtensor

    async def test_get_highest_validator_error(self, chain_sync_instance):
        """Test error handling in get_highest_stake_validator_bucket"""
        # Make metagraph raise an exception on access
        chain_sync_instance.metagraph.uids = MagicMock(
            side_effect=Exception("Test error")
        )

        # Should return None, None on error
        bucket, uid = await chain_sync_instance._get_highest_stake_validator_bucket()
        assert bucket is None
        assert uid is None


async def test_periodic_commitment_fetcher():
    """
    Test that the periodic commitment fetcher in ChainSync calls
    get_commitments repeatedly.
    """
    hparams = SimpleNamespace(
        blocks_per_window=100,
        topk_peers=10,
        minimum_peers=1,
        max_topk_peers=5,
        eval_stake_threshold=20000,
    )

    commitment_calls = 0

    async def fake_get_commitments(*args, **kwargs):
        nonlocal commitment_calls
        commitment_calls += 1
        # Return a dummy commitment for each call.
        return {
            commitment_calls: Bucket(
                name=f"bucket{commitment_calls}",
                account_id=f"acc{commitment_calls}",
                access_key_id="dummy_key",
                secret_access_key="dummy_secret",
            )
        }

    # Patch ChainSync.get_commitments and bt.subtensor.
    with patch(
        "tplr.chain_sync.ChainSync.get_commitments",
        new=AsyncMock(side_effect=fake_get_commitments),
    ):
        with patch("tplr.chain_sync.bt.subtensor", return_value=MockSubtensor()):
            # Create a metagraph instance from our mocks and attach a dummy sync.
            metagraph = MockMetagraph()
            metagraph.sync = lambda subtensor: None

            chain_sync = ChainSync(
                config=MagicMock(),
                netuid=1,
                metagraph=metagraph,
                hparams=hparams,
                fetch_interval=0.1,
                wallet=MockWallet(),
            )

            fetch_task = asyncio.create_task(
                chain_sync._fetch_commitments_periodically()
            )
            await asyncio.sleep(0.35)  # allow for a few iterations
            fetch_task.cancel()
            try:
                await fetch_task
            except asyncio.CancelledError:
                pass

    # Expect at least 3 calls (0.35/0.1 â‰ˆ 3-4 iterations)
    assert commitment_calls >= 3


async def test_update_peers_with_buckets():
    """
    Test that ChainSync correctly updates its peers list based on the intersection
    of active peers and available commitment buckets.
    """
    hparams = SimpleNamespace(
        blocks_per_window=100, topk_peers=10, minimum_peers=1, max_topk_peers=5
    )
    chain_sync = ChainSync(
        config=MagicMock(),
        netuid=1,
        metagraph=MagicMock(),
        hparams=hparams,
        wallet=MagicMock(),
    )

    # Set some dummy commitments and active peers.
    chain_sync.commitments = {
        1: Bucket(
            name="bucket1",
            account_id="acc1",
            access_key_id="k1",
            secret_access_key="s1",
        ),
        2: Bucket(
            name="bucket2",
            account_id="acc2",
            access_key_id="k2",
            secret_access_key="s2",
        ),
    }
    # Active peers include one extra peer (3) that lacks a commitment.
    chain_sync.active_peers = {1, 2, 3}
    # Update peers by taking an intersection.
    chain_sync.peers = list(
        chain_sync.active_peers.intersection(chain_sync.commitments.keys())
    )

    # Only UIDs 1 and 2 should be in peers.
    assert set(chain_sync.peers) == {1, 2}


async def test_window_update_on_block():
    """
    Test that updating the current block value leads to recalculating the current window.
    """
    hparams = SimpleNamespace(
        blocks_per_window=10, topk_peers=10, minimum_peers=1, max_topk_peers=5
    )
    chain_sync = ChainSync(
        config=MagicMock(),
        netuid=1,
        metagraph=MagicMock(),
        hparams=hparams,
        wallet=MagicMock(),
    )
    # Initialize current block and window.
    chain_sync.current_block = 5
    chain_sync.current_window = 0

    # Simulate a block update:
    def fake_block_update(new_block: int):
        chain_sync.current_block = new_block
        new_window = int(new_block / hparams.blocks_per_window)
        if new_window != chain_sync.current_window:
            chain_sync.current_window = new_window

    fake_block_update(25)  # 25 // 10 = 2
    assert chain_sync.current_window == 2


async def test_get_bucket_not_found():
    """
    Test that get_bucket returns None for an unknown UID.
    """
    hparams = SimpleNamespace(
        blocks_per_window=100, topk_peers=10, minimum_peers=1, max_topk_peers=5
    )
    chain_sync = ChainSync(
        config=MagicMock(),
        netuid=1,
        metagraph=MagicMock(),
        hparams=hparams,
        wallet=MagicMock(),
    )
    # Set commitments with UID 1 only.
    chain_sync.commitments = {
        1: Bucket(
            name="bucket1",
            account_id="acc1",
            access_key_id="key1",
            secret_access_key="secret1",
        )
    }
    bucket = chain_sync.get_bucket(999)
    assert bucket is None


# ------------------------------------------------------------
# Test get_commitments() with various commitment cases.
# ------------------------------------------------------------


@pytest.mark.asyncio
async def test_get_commitments_various_cases():
    """
    Tests get_commitments() with:
      - Valid commitment (length 128) for uid=1.
      - Empty commitment for uid=2.
      - Invalid length commitment for uid=3.
      - Exception raised for uid=4.
    Only uid=1 should yield a Bucket.
    """
    # Create a dummy metagraph with uids.
    metagraph = MagicMock()
    metagraph.uids = torch.tensor([1, 2, 3, 4])

    # Instantiate ChainSync.
    cs = ChainSync(
        config=MagicMock(),
        netuid=1,
        metagraph=metagraph,
        hparams=SimpleNamespace(),
        wallet=MagicMock(),
        fetch_interval=1,
    )

    # Create a fake subtensor with custom get_commitment.
    class FakeSubtensor:
        def get_commitment(self, netuid, uid):
            if uid == 1:
                return "a" * 128  # valid
            elif uid == 2:
                return ""  # empty
            elif uid == 3:
                return "b" * 50  # invalid length
            elif uid == 4:
                raise Exception("dummy error")

    fake_subtensor = FakeSubtensor()

    with patch("tplr.chain_sync.bt.subtensor", return_value=fake_subtensor):
        commitments = await cs.get_commitments()

    # Only uid 1 should be added.
    assert 1 in commitments
    assert commitments[1].name == "a" * 32
    assert 2 not in commitments
    assert 3 not in commitments
    assert 4 not in commitments


# ------------------------------------------------------------
# Test update_peers_with_buckets() and set_gather_peers()
# ------------------------------------------------------------


def test_update_peers_with_empty_active_peers():
    """
    If active_peers is empty, update_peers_with_buckets() should warn
    and leave peers empty while marking previously active peers as inactive.
    """
    metagraph = MagicMock()
    metagraph.uids = torch.tensor([1, 2, 3])
    metagraph.S = torch.tensor([100, 200, 300])
    metagraph.I = torch.tensor([10, 20, 30])

    hparams = SimpleNamespace(
        eval_stake_threshold=20000, topk_peers=10, minimum_peers=3, max_topk_peers=10
    )
    cs = ChainSync(
        config=MagicMock(),
        netuid=1,
        metagraph=metagraph,
        hparams=hparams,
        wallet=MagicMock(),
        fetch_interval=1,
    )

    # Prepopulate eval_peers so we can see the difference.
    cs.eval_peers = {1: 5, 2: 3}
    cs.active_peers = set()  # empty active peers

    cs.update_peers_with_buckets()
    assert cs.peers == []  # No peers gathered.
    # All previously active should now be inactive.
    assert cs.inactive_peers == {1, 2}


def test_update_peers_with_nonempty_active_peers():
    """
    With non-empty active_peers, update_peers_with_buckets() should filter
    eval_peers based on stake threshold and set gather peers ordering by incentive.
    """
    metagraph = MagicMock()
    metagraph.uids = torch.tensor([1, 2, 3])
    # Stakes: uid1=15000, uid2=25000, uid3=18000.
    metagraph.S = torch.tensor([15000, 25000, 18000])
    # Incentives: uid1=100, uid2=200, uid3=50.
    metagraph.I = torch.tensor([100, 200, 50])

    hparams = SimpleNamespace(
        eval_stake_threshold=20000, topk_peers=10, minimum_peers=3, max_topk_peers=10
    )
    cs = ChainSync(
        config=MagicMock(),
        netuid=1,
        metagraph=metagraph,
        hparams=hparams,
        wallet=MagicMock(),
        fetch_interval=1,
    )

    cs.active_peers = {1, 2, 3}
    cs.eval_peers = {}  # start with empty eval_peers.

    cs.update_peers_with_buckets()
    # Only uid=1 and uid=3 have stakes <=20000.
    assert cs.eval_peers == {1: 1, 3: 1}
    # set_gather_peers works on active_peers regardless.
    # Incentives sorted descending: [(2,200), (1,100), (3,50)].
    # With minimum_peers=3, peers list should be all: [2, 1, 3].
    assert cs.peers == [2, 1, 3]


def test_set_gather_peers_empty():
    """
    If there are no active peers, set_gather_peers() should set peers to empty.
    """
    metagraph = MagicMock()
    metagraph.uids = torch.tensor([1, 2])
    metagraph.I = torch.tensor([50, 60])
    hparams = SimpleNamespace(topk_peers=10, minimum_peers=3, max_topk_peers=10)
    cs = ChainSync(
        config=MagicMock(),
        netuid=1,
        metagraph=metagraph,
        hparams=hparams,
        wallet=MagicMock(),
        fetch_interval=1,
    )

    cs.active_peers = set()
    cs.set_gather_peers()
    assert cs.peers == []


# ------------------------------------------------------------
# Test _get_highest_stake_validator_bucket()
# ------------------------------------------------------------


@pytest.mark.asyncio
async def test_get_highest_stake_validator_bucket_valid():
    """
    When a valid validator exists (T > 0), _get_highest_stake_validator_bucket()
    should return the bucket for the highest staked validator.
    """
    metagraph = MagicMock()
    metagraph.uids = torch.tensor([1, 2, 3])
    # Stakes: 100, 200, 50.
    metagraph.S = torch.tensor([100, 200, 50])
    # Only uid 2 is a validator.
    metagraph.T = torch.tensor([0, 1, 0])

    hparams = SimpleNamespace()
    cs = ChainSync(
        config=MagicMock(),
        netuid=1,
        metagraph=metagraph,
        hparams=hparams,
        wallet=MagicMock(),
        fetch_interval=1,
    )

    valid_commitment = "c" * 128
    cs.commitments = {
        2: Bucket(
            name=valid_commitment[:32],
            account_id=valid_commitment[:32],
            access_key_id=valid_commitment[32:64],
            secret_access_key=valid_commitment[64:],
        )
    }

    bucket, uid = await cs._get_highest_stake_validator_bucket()
    assert uid == 2
    assert bucket is not None


@pytest.mark.asyncio
async def test_get_highest_stake_validator_bucket_no_validators():
    """
    If no validators are found (all T values are 0), the method should return (None, None).
    """
    metagraph = MagicMock()
    metagraph.uids = torch.tensor([1, 2, 3])
    metagraph.S = torch.tensor([100, 200, 50])
    metagraph.T = torch.tensor([0, 0, 0])

    hparams = SimpleNamespace()
    cs = ChainSync(
        config=MagicMock(),
        netuid=1,
        metagraph=metagraph,
        hparams=hparams,
        wallet=MagicMock(),
        fetch_interval=1,
    )

    bucket, uid = await cs._get_highest_stake_validator_bucket()
    assert bucket is None
    assert uid is None


@pytest.mark.asyncio
async def test_get_highest_stake_validator_bucket_no_metagraph():
    """
    If metagraph is None, _get_highest_stake_validator_bucket() should return (None, None).
    """
    cs = ChainSync(
        config=MagicMock(),
        netuid=1,
        metagraph=None,
        hparams=SimpleNamespace(),
        wallet=MagicMock(),
        fetch_interval=1,
    )
    bucket, uid = await cs._get_highest_stake_validator_bucket()
    assert bucket is None
    assert uid is None


@pytest.mark.asyncio
async def test_get_highest_stake_validator_bucket_exception():
    """
    Simulate an exception (e.g., in metagraph.uids.tolist()) so that the method
    returns (None, None).
    """
    metagraph = MagicMock()
    # Make uids.tolist() raise an exception.
    metagraph.uids = property(
        lambda self: (_ for _ in ()).throw(Exception("dummy exception"))
    )

    cs = ChainSync(
        config=MagicMock(),
        netuid=1,
        metagraph=metagraph,
        hparams=SimpleNamespace(),
        wallet=MagicMock(),
        fetch_interval=1,
    )

    bucket, uid = await cs._get_highest_stake_validator_bucket()
    assert bucket is None
    assert uid is None


@pytest.mark.asyncio
async def test_get_commitments_outer_exception():
    """
    Simulate an outer exception by patching bt.subtensor so that it raises.
    This covers the outer try/except in get_commitments().
    """
    metagraph = MagicMock()
    metagraph.uids = torch.tensor([1])
    cs = ChainSync(
        config=MagicMock(),
        netuid=1,
        metagraph=metagraph,
        hparams=SimpleNamespace(),
        wallet=MagicMock(),
        fetch_interval=1,
    )
    with patch(
        "tplr.chain_sync.bt.subtensor", side_effect=Exception("outer exception")
    ):
        commitments = await cs.get_commitments()
        # Expect the method to return an empty dict.
        assert commitments == {}


@pytest.mark.asyncio
async def test_get_commitments_logger_invalid_length(caplog):
    """
    Test that a commitment with an invalid length triggers the
    logger.error and skips adding the bucket.
    Covers lines 128-130 where the invalid length branch is taken.
    """
    metagraph = MagicMock()
    metagraph.uids = torch.tensor([1])
    cs = ChainSync(
        config=MagicMock(),
        netuid=1,
        metagraph=metagraph,
        hparams=SimpleNamespace(),
        wallet=MagicMock(),
        fetch_interval=1,
    )

    class FakeSubtensor:
        def get_commitment(self, netuid, uid):
            # Return a string whose length is not 128.
            return "short_commitment"  # length = 16

    with patch("tplr.chain_sync.bt.subtensor", return_value=FakeSubtensor()):
        await cs.get_commitments()

    # Check that logger.error recorded a message about invalid commitment length.
    error_msgs = [
        record.message for record in caplog.records if record.levelname == "ERROR"
    ]
    found = any("Invalid commitment length" in msg for msg in error_msgs)
    assert found


@pytest.mark.asyncio
async def test_get_commitments_empty_commitment():
    """
    Test that if get_commitment returns an empty string,
    the method skips it without error.
    This covers the branch for `if not commitment or len(commitment) == 0`.
    """
    metagraph = MagicMock()
    metagraph.uids = torch.tensor([1])
    cs = ChainSync(
        config=MagicMock(),
        netuid=1,
        metagraph=metagraph,
        hparams=SimpleNamespace(),
        wallet=MagicMock(),
        fetch_interval=1,
    )

    class FakeSubtensor:
        def get_commitment(self, netuid, uid):
            return ""  # empty commitment

    with patch("tplr.chain_sync.bt.subtensor", return_value=FakeSubtensor()):
        commitments = await cs.get_commitments()
        # No valid commitment, so expect an empty dict.
        assert commitments == {}


@pytest.mark.asyncio
async def test_get_commitments_no_metagraph():
    """
    Test that if metagraph is None, get_commitments() triggers an exception
    and returns an empty dict.
    Patching bt.subtensor to prevent any network call.
    """
    cs = ChainSync(
        config=MagicMock(),
        netuid=1,
        metagraph=None,
        hparams=SimpleNamespace(),
        wallet=MagicMock(),
        fetch_interval=1,
    )
    with patch("tplr.chain_sync.bt.subtensor", return_value=MagicMock()):
        commitments = await cs.get_commitments()
    assert commitments == {}
